{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b70271-e574-4ddc-b34d-b14d99a3e5cb",
   "metadata": {},
   "source": [
    "# Simple diffusion\n",
    "This is a simple diffusion model heavily based on [minDiffusion](https://github.com/cloneofsimo/minDiffusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc4462-c498-418a-9f71-ed5ef19d545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time, math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06918d5-f94d-407b-9865-78c605765550",
   "metadata": {},
   "source": [
    "## Constants\n",
    "Constants used in the diffusion process and training are defined here. [Full reproducibility requires more than just setting the seed.](https://pytorch.org/docs/stable/notes/randomness.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca1190-408e-4df3-bdd7-0764eb534512",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_OUT_DIR = r\"D:\\Projs\\proj\\simple-diff\\models\"\n",
    "SAMPLE_OUT_DIR = r\"D:\\Projs\\proj\\simple-diff\\samples\"\n",
    "\n",
    "# Diffusion\n",
    "NOISE_STEPS = 1000\n",
    "BETA_START = 1e-4\n",
    "BETA_END = 2e-2\n",
    "\n",
    "# Training\n",
    "INIT_LR = 1e-5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3000\n",
    "\n",
    "# Low effort reproducibility\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1fb82-590d-4ea9-995a-a9c94e639cf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "The dataset used is CIFAR-10, a collection of 3 channel 32 by 32 pixel images. The transform normalizes the input to range of \\[-1, 1\\]. For testing purposes a single batch can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5af948-8703-47e7-8bf2-17fcdfceebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "dataset = CIFAR10(\n",
    "    \"../../datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=data_transforms\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733b9ad-c123-47c0-a046-5ef61ac96a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model by overfitting to one batch\n",
    "subset_indices = range(BATCH_SIZE)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(subset_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591a196-2256-48de-8665-9fd54b01d54a",
   "metadata": {},
   "source": [
    "## Diffusion\n",
    "The diffusion class implements forward diffusion (noise image generation) and sampling (denoising) using a linear schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75dd89-214c-4287-9393-7f79bbbdfc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion():\n",
    "    def __init__(self, noise_steps=NOISE_STEPS, beta_start=BETA_START, beta_end=BETA_END, device=DEVICE):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.device = device\n",
    "\n",
    "        self.alpha, self.beta, self.alcum = self.linear_schedule()\n",
    "        self.sqrt_beta = torch.sqrt(self.beta)\n",
    "        self.sqrt_alcum = torch.sqrt(self.alcum)\n",
    "        self.rec_sqrt_alpha = 1. / torch.sqrt(self.alpha)\n",
    "        self.sqrt_1sub_alcum = torch.sqrt(1 - self.alcum)\n",
    "        self.beta_over_sqrt_1sub_alcum = self.beta / self.sqrt_1sub_alcum\n",
    "\n",
    "\n",
    "    def linear_schedule(self):\n",
    "        beta = torch.linspace(self.beta_start, self.beta_end, self.noise_steps + 1, device=self.device)\n",
    "        alpha = 1. - beta\n",
    "        alpha_cum = torch.cumprod(alpha, axis=0)\n",
    "        return alpha, beta, alpha_cum\n",
    "\n",
    "\n",
    "    def forward(self, x_0):\n",
    "        t = torch.randint(1, self.noise_steps + 1, (x_0.shape[0],), device=self.device)\n",
    "        noise = torch.randn_like(x_0, device=self.device)\n",
    "        x_t = self.sqrt_alcum[t, None, None, None] * x_0 + self.sqrt_1sub_alcum[t, None, None, None] * noise\n",
    "        return x_t, noise, t\n",
    "\n",
    "\n",
    "    def sample(self, sample_num, img_dims, model):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((sample_num, *img_dims), device=self.device)\n",
    "            for i in reversed(range(1, self.noise_steps)):\n",
    "                t = torch.full(size=(sample_num,), fill_value=i, device=self.device)\n",
    "                predicted_noise = model(x, t)\n",
    "                noise = torch.randn_like(x)\n",
    "                rec_sqrt_alpha = self.rec_sqrt_alpha[t, None, None, None]\n",
    "                beta_over_sqrt_1sub_alcum = self.beta_over_sqrt_1sub_alcum[t, None, None, None]\n",
    "                sqrt_beta = self.sqrt_beta[t, None, None, None]\n",
    "                x = rec_sqrt_alpha * (x - beta_over_sqrt_1sub_alcum * predicted_noise) + sqrt_beta * noise\n",
    "        return x\n",
    "\n",
    "\n",
    "diffusion = Diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90651f4-4992-4fc5-83d4-1c2232a8cc2a",
   "metadata": {},
   "source": [
    "## Model\n",
    "The denoising model is a simple U-Net structure based on [minDiffusion](https://github.com/cloneofsimo/minDiffusion). It uses sinusoidal position embeddings to encode time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b654c-46f5-4a38-8852-4c0e3abb529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    \"\"\"Taken verbatim from https://huggingface.co/blog/annotated-diffusion\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f5966-a3d5-4b6b-98d2-6cac33aa62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Simple convolutional network based on NaiveUnet from minDiffusion.\n",
    "\"\"\"\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, self.output_channels, 3, 1, 1),\n",
    "            nn.GroupNorm(8, self.output_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.output_channels, self.output_channels, 3, 1, 1),\n",
    "            nn.GroupNorm(8, self.output_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.output_channels, self.output_channels, 3, 1, 1),\n",
    "            nn.GroupNorm(8, self.output_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(self.input_channels, self.output_channels),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.input_channels, self.output_channels, 2, 2),\n",
    "            ConvBlock(self.output_channels, self.output_channels),\n",
    "            ConvBlock(self.output_channels, self.output_channels)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        x = torch.cat((x, residual), dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.first = ConvBlock(self.input_channels, self.hidden_size)\n",
    "        self.sin_time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(2 * self.hidden_size),\n",
    "            nn.Linear(2 * self.hidden_size, 2 * self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * self.hidden_size, 2 * self.hidden_size),\n",
    "        )\n",
    "        \n",
    "        self.down1 = DownBlock(self.hidden_size, self.hidden_size)\n",
    "        self.down2 = DownBlock(self.hidden_size, 2 * self.hidden_size)\n",
    "        self.down3 = DownBlock(2 * self.hidden_size, 2 * self.hidden_size)\n",
    "        \n",
    "        self.avg = nn.Sequential(\n",
    "            nn.AvgPool2d(4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * self.hidden_size, 2 * self.hidden_size, 4, 4),\n",
    "            nn.GroupNorm(8, 2 * self.hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up1 = UpBlock(4 * self.hidden_size, 2 * self.hidden_size)\n",
    "        self.up2 = UpBlock(4 * self.hidden_size, self.hidden_size)\n",
    "        self.up3 = UpBlock(2 * self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        self.out = nn.Conv2d(2 * self.hidden_size, self.output_channels, 3, 1, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        x = self.first(x)\n",
    "        embeddings = self.sin_time_mlp(t).view(-1, 2 * self.hidden_size, 1, 1)\n",
    "        \n",
    "        down1 = self.down1(x)\n",
    "        down2 = self.down2(down1)\n",
    "        down3 = self.down3(down2)\n",
    "        \n",
    "        avg = self.avg(down3)\n",
    "        up0 = self.up0(avg + embeddings)\n",
    "        \n",
    "        up1 = self.up1(up0, down3)\n",
    "        up2 = self.up2(up1, down2)\n",
    "        up3 = self.up3(up2, down1)\n",
    "        out = self.out(torch.cat((up3, x), dim=1))\n",
    "        return out     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60329449-5ae1-4eba-911b-23a435af666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet(3,3,128).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de45ae-86eb-455a-86f2-d0dd2766ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81acd6-47be-4579-9476-f4719ee8476e",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training is done by taking random timesteps and learning the noise. The test model was trained by overfitting on a single batch to check model functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6993a9-1cc0-496d-84a7-4df60cd93f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0, EPOCHS):\n",
    "    model.train()\n",
    "    pbar = tqdm(dataloader)\n",
    "    for x_0, _ in pbar:\n",
    "        x_0 = x_0.to(DEVICE)\n",
    "        x_t, noise, t = diffusion.forward(x_0)\n",
    "        noise_hat = model(x_t, t)\n",
    "        loss = loss_fn(noise, noise_hat)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.set_postfix(EPOCH=e, MSE=loss.item())\n",
    "print(f\"Training loop finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977f299-30f0-4745-b5e1-bc128bfa39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{MODEL_OUT_DIR}/{time.time_ns() // 1_000_000}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2d74a-a8d5-47ab-89c7-24c7d8d5fda1",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Sampling is done in a batch in an attempt to generate some acceptable images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792993fa-5736-4ce1-b40f-15f5a625f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample = diffusion.sample(8, (3, 32, 32), model)\n",
    "    grid = make_grid(sample, normalize=True, value_range=(-1, 1), nrow=4)\n",
    "    save_image(grid, f\"{SAMPLE_OUT_DIR}/sample_cifar_{time.time_ns() // 1_000_000}.png\")\n",
    "print(\"Images saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f7cc8-66d6-47ef-87ac-08261384eee5",
   "metadata": {},
   "source": [
    "## Loading\n",
    "Loading the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67480b88-7f73-4f8c-8c78-02f1512765cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet(3,3,128).to(DEVICE)\n",
    "model.load_state_dict(torch.load(f\"{MODEL_OUT_DIR}/1686675513310.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
